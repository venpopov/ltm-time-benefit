{
  "hash": "e307a3fff671e9c9583286c0581d4f4f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bootstrapping data and fits for parameter uncertainty estimation\"\nformat: html\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(targets)\nlibrary(GGally)\nlibrary(kableExtra)\n\n# load \"R/*\" scripts and saved R objects from the targets pipeline\ntar_source()\ntar_load(c(exp1_data, exp2_data, exp1_data_agg, exp2_data_agg, exp3_data_agg))\nset.seed(213)\n\n# make sure that if the model fails to converge, it doesn't stop the whole process\nsafe_boot_est <- purrr::safely(boot_est)\n```\n:::\n\n\n\n\n\n## Overview\n\nTo get an estimate of the uncertainty in the parameter estimates, we can use bootstrapping. This involves resampling the data with replacement and fitting the model to each resampled dataset. We do this:\n\n1. Resample the IDs of participants in the dataset with replacement.\n2. For each subject, calculate the proportion of correct responses in each condtion and resample the observed counts from a binomial distribution with the probability of success equal to the proportion of correct responses.\n3. Estimate the model parameters from the resampled data.\n4. Repeat steps 1-3 1000 times to get a distribution of parameter estimates.\n\n## Experiment 1\n\nFor now I've done it just for experiment 1. Here are the results:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_asy <- run_or_load(\n  do.call(rbind, replicate(1000, safe_boot_est(exp1_data)$result)),\n  \"output/res_boot1000_asy.rds\")\n\nplot_bootstrap_results(res_asy)\n```\n\n::: {.cell-output-display}\n![](model3_bootstrap_files/figure-html/exp1_boot-1.png){width=672}\n:::\n:::\n\n\n\n\nand here are the 95% highest density intervals for the rate parameters\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(HDInterval::hdi(res_asy$rate), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlower upper \n0.056 0.213 \nattr(,\"credMass\")\n[1] 0.95\n```\n\n\n:::\n:::\n\n\n\n\nfrom these bootstrap estimates, we can calculate how long it would take for 50% of the resources to recover from 0 (also see [here](model3_basic_fits.qmd#summary)). \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_est <- -log(0.5) / res_asy$rate\n\nround(HDInterval::hdi(t_est), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n lower  upper \n 2.799 10.676 \nattr(,\"credMass\")\n[1] 0.95\n```\n\n\n:::\n:::\n\n\n\n\nIt would take on average $6.1883827$ seconds for 50% of the resources to recover from 0, with a 95% HDI of $2.7987571, 10.67613$.\n",
    "supporting": [
      "model3_bootstrap_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}