{
  "hash": "98c1a7b975dc3d4cf03c4a0e9d5652a5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Parameter identifiability\"\nformat: \n  html:\n    html-table-processing: none\n---\n\n\n## Overview\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(targets)\nlibrary(GGally)\nlibrary(kableExtra)\ntar_source()\ntar_load_everything()\n```\n:::\n\n\nIn [the initial modeling notebook](modelling_edas_approach.qmd#problem-with-parameter-identifiability), I discovered some problems with parameter identifiability. Here I will explore this issue further.\n\nInitially I ran the model described in the May 13, 2024 draft with 100 different starting parameters. Here are 5 sets of very different best-fitting parameters that produce nearly identical fits as measured by the negative log-likelihood (deviance):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfits <- readRDS(\"output/five_parsets_exp2.rds\")\nfits$set <- paste0(\"set\", 1:5)\n\nfits[, 1:6] |>\n  as.data.frame() |>\n  `rownames<-`(fits$set) |>\n  kbl() %>%\n  kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> prop </th>\n   <th style=\"text-align:right;\"> prop_ltm </th>\n   <th style=\"text-align:right;\"> rate </th>\n   <th style=\"text-align:right;\"> tau </th>\n   <th style=\"text-align:right;\"> gain </th>\n   <th style=\"text-align:right;\"> deviance </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> set1 </td>\n   <td style=\"text-align:right;\"> 0.098 </td>\n   <td style=\"text-align:right;\"> 0.815 </td>\n   <td style=\"text-align:right;\"> 0.006 </td>\n   <td style=\"text-align:right;\"> 0.084 </td>\n   <td style=\"text-align:right;\"> 96.954 </td>\n   <td style=\"text-align:right;\"> 40.377 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> set2 </td>\n   <td style=\"text-align:right;\"> 0.132 </td>\n   <td style=\"text-align:right;\"> 0.818 </td>\n   <td style=\"text-align:right;\"> 0.009 </td>\n   <td style=\"text-align:right;\"> 0.108 </td>\n   <td style=\"text-align:right;\"> 54.078 </td>\n   <td style=\"text-align:right;\"> 40.429 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> set3 </td>\n   <td style=\"text-align:right;\"> 0.155 </td>\n   <td style=\"text-align:right;\"> 0.820 </td>\n   <td style=\"text-align:right;\"> 0.010 </td>\n   <td style=\"text-align:right;\"> 0.123 </td>\n   <td style=\"text-align:right;\"> 40.135 </td>\n   <td style=\"text-align:right;\"> 40.491 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> set4 </td>\n   <td style=\"text-align:right;\"> 0.173 </td>\n   <td style=\"text-align:right;\"> 0.822 </td>\n   <td style=\"text-align:right;\"> 0.011 </td>\n   <td style=\"text-align:right;\"> 0.133 </td>\n   <td style=\"text-align:right;\"> 32.738 </td>\n   <td style=\"text-align:right;\"> 40.556 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> set5 </td>\n   <td style=\"text-align:right;\"> 0.215 </td>\n   <td style=\"text-align:right;\"> 0.826 </td>\n   <td style=\"text-align:right;\"> 0.013 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 21.967 </td>\n   <td style=\"text-align:right;\"> 40.772 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe can see that they all produce nearly identical predictions (the lines are the model predictions, the points are the data):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfits |>\n  mutate(pred = map2(fit, data, \\(x, y) predict(x, y, group_by = c(\"chunk\", \"gap\")))) |>\n  unnest(c(data, pred)) |>\n  mutate(gap = as.factor(gap)) |>\n  ggplot(aes(x = gap, y = p_correct, color = chunk)) +\n  geom_point() +\n  geom_line(aes(y = pred, linetype = set, group = interaction(chunk, set))) +\n  scale_color_discrete(\"First chunk LTM?\") +\n  scale_linetype_discrete(\"Parameter set\") +\n  facet_grid(~itemtype) +\n  theme_pub()\n```\n\n::: {.cell-output-display}\n![](par-identifiability_files/figure-html/plot five fits-1.png){width=816}\n:::\n:::\n\n\nThe plot below shows the strong nearly linear trade-offs between the parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfits |>\n  select(prop, rate, tau, gain) |>\n  ggpairs(\n    diag = list(continuous = \"blankDiag\"),\n    upper = list(continuous = \"points\")\n  ) +\n  theme_pub() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](par-identifiability_files/figure-html/plot par correlations-1.png){width=816}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(rate ~ prop, data = fits) |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = rate ~ prop, data = fits)\n\nResiduals:\n         1          2          3          4          5 \n-0.0005030  0.0005165  0.0001767  0.0001282 -0.0003183 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept) 0.0007944  0.0008582   0.926  0.42285   \nprop        0.0582507  0.0053801  10.827  0.00169 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0004721 on 3 degrees of freedom\nMultiple R-squared:  0.975,\tAdjusted R-squared:  0.9667 \nF-statistic: 117.2 on 1 and 3 DF,  p-value: 0.001686\n```\n\n\n:::\n:::\n\n\n## Highest rate for which the model fit is still good\n\n\n#| label: rate fits\n\n",
    "supporting": [
      "par-identifiability_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}