---
title: "Playground"
format: html
---

## Contraint/Unconstrain vectorizing tests

I want to build a constrain/unconstrain function. Here' are two versions. The second one is vectorized

```{r}
source("R/utils.R")

constrain <- function(x, lb, ub) {
  if (is.infinite(lb) && is.infinite(ub)) {
    x
  } else if (is.infinite(ub)) {
    exp(x) + lb
  } else if (is.infinite(lb)) {
    ub - exp(x)
  } else {
    inv_logit(x, lb = lb, ub = ub)
  }
}

constrain_vec <- function(x, lb, ub) {
  ifelse(is.infinite(lb) & is.infinite(ub), x,
    ifelse(is.infinite(ub), exp(x) + lb,
      ifelse(is.infinite(lb), ub - exp(x),
        inv_logit(x, lb = lb, ub = ub)
      )
    )
  )
}

constrain_vec2 <- function(x, lb, ub) {
  if (length(lb) == 1 && length(ub) == 1 && is.infinite(lb) && is.infinite(ub)) {
    return(x)
  }

  dplyr::case_when(
    is.infinite(lb) & is.infinite(ub) ~ x,
    is.infinite(ub) ~ exp(x) + lb,
    is.infinite(lb) ~ ub - exp(x),
    .default = inv_logit(x, lb = lb, ub = ub)
  )
}
```

Let's test them

```{r}
library(purrr)
library(microbenchmark)
N <- 1000
x <- c(log(rexp(N)), logit(runif(N)), rnorm(N))
lb <- c(rep(0, N), rep(0, N), rep(-Inf, N))
ub <- c(rep(Inf, N), rep(1, N), rep(Inf, N))

microbenchmark(
  pmap_dbl(list(x, lb, ub), constrain),
  constrain_vec(x, lb, ub),
  constrain_vec2(x, lb, ub),
  times = 100,
  check = "equivalent"
)
```

Yes, the vectorized version is much faster. But it's not as readable as the first one. The dplyr version is cleanest and just as fast.

What about if the bounds were fixed?

```{r}
microbenchmark(
  (function(x) x)(x),
  pmap_dbl(list(x, -Inf, Inf), constrain),
  constrain_vec2(x, -Inf, Inf),
  times = 100,
  check = "equivalent"
)
```

## A better version of optim

```{r}
source("R/utils.R")
fn <- function(par, x) {
  tryCatch(
    {
      -sum(bmm::dmixture2p(x, mu = 0, kappa = par[1], pMem = par[2], log = TRUE))
    },
    error = function(e) NA
  )
}
x <- bmm::rmixture2p(100)

microbenchmark(
  optim(c(5, 0.1), fn, x = x),
  optim2(c(5, 0.1), fn, x = x, lower = c(0, 0), upper = c(Inf, 1)),
  times = 100
)
```

How well does it work for different starting values?

```{r}
optim3 <- function(par, fn, ...) {
  fn2 <- function(par, ...) {
    par <- c(exp(par[1]), inv_logit(par[2]))
    fn(par, ...)
  }

  start <- c(log(par[1]), logit(par[2]))
  res <- optim(start, fn2, ..., control = list(parscale = c(1, 0.1)))
  c(exp(res$par[1]), inv_logit(res$par[2]))
}

set.seed(123)
x <- bmm::rmixture2p(100)
start <- as.matrix(expand.grid(
  kappa = c(1, 5, 10),
  pMem = c(0.6, 0.9, 0.99)
))

res <- apply(start, 1, optim3, fn = fn, x = x)
res

mixtur::fit_mixtur(data.frame(response = x, target = 0, id = 1), model = "2_component", unit = "radians")

microbenchmark(
  apply(start, 1, optim3, fn = fn, x = x),
  apply(start, 1, optim2, fn = fn, x = x, lower = c(0, 0), upper = c(Inf, 1)),
  times = 100
)
```
